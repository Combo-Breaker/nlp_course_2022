{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asqx1WL55TLq"
   },
   "source": [
    "\n",
    "<h1><center>Многоязычная классификация текстов на основе BERT</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfSh7G1XLyQk"
   },
   "source": [
    "Мы продолжим знакомство с моделями на основе архитектуры Трансформер. \n",
    "На этом занятии мы рассмотрим классификатор на основе модели RoBERTa (модель на базе BERT), дообученный для решения задачи Natural Language Inference (NLI). В этой задаче нам требуется предсказать, если ли логическая связь между двумя предложениями: следует ли одного из другого.  Этот классификатор, предобученный на задаче NLI, позволит нам решать задачу классификации в Zero-shot постановке. В такой постановке модели НЕ требуется обучение на размеченных данных, поскольку любую задачу мы можем свести к задаче NLI –- мы рассмотрим, как именно в примерах ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfSh7G1XLyQk"
   },
   "source": [
    "Мы загрузим заранее обученный классификатор и будем использовать его, чтообы классифицировать тексты на нужные нам классы. \n",
    "\n",
    "Два важных отличия рассматриваемой сегодня модели от тех, с которыми мы работали на предыдущих занятиях:\n",
    "- Подход zero-shot не требует обучения модели, нам следует лишь подать классификатору текст и названия нужных нам классов. Модель будет строить предсказание на основе своего внутреннего представления, обученного заранее.\n",
    "- Данная модель многоязычна. Мы будем работать с текстами, написанными на разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEVmW7u3Nc6G"
   },
   "source": [
    "## Классификация текстов на английском языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvaDv7ReLqU9"
   },
   "source": [
    "Установим библиотеку transformers и загрузим модуль pipeline, в котором находится нужная нам модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTBP_QYuu6tc"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiU_ES5tzpMH"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spkccRiv0CB3"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "# classifier = pipeline(\"zero-shot-classification\", device=0) # to utilize GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWiovVJG9ei_"
   },
   "source": [
    "\n",
    "С помощью этой модели мы можем классифицировать тексты как принадлежащие или не принадлежащие одному из нужных нам классов.\n",
    "\n",
    "По умолчанию предполагается, что текст принадлежит ровно к одному из объявленных классов, а модель возвращает вероятности каждого из классов, которые в сумме равны 1.\n",
    "\n",
    "Посмотрим простой пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "hkfE6NRA0Dzy",
    "outputId": "8b3f9e37-3e46-4b25-813b-c5fa7bbc3c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politics', 'economics', 'public health'],\n",
       " 'scores': [0.972518801689148, 0.01458414364606142, 0.012897025793790817],\n",
       " 'sequence': 'Who are you voting for in 2020?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"politics\", \"public health\", \"economics\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGXwxxyn9nOC"
   },
   "source": [
    "Модель также может решать задачу многоклассоовой классификации, определяя для каждого класса, принадлежит ли к нему текст или нет. \n",
    "В этом случае модель возвращает вероятности каждого из классов независимо. Нам понадобиться добавить парамерт ```multi_class=True``` в вызов функции. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "ZvZeVb2h5RX0",
    "outputId": "9ba085bf-4c52-4011-9c51-3a0adeddd3a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politics', 'elections', 'public health', 'economics'],\n",
       " 'scores': [0.972069501876831,\n",
       "  0.967610776424408,\n",
       "  0.03248710557818413,\n",
       "  0.0061644683592021465],\n",
       " 'sequence': 'Who are you voting for in 2020?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"politics\", \"public health\", \"economics\", \"elections\"]\n",
    "\n",
    "classifier(sequence, candidate_labels, multi_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLLeDT1r9-yQ"
   },
   "source": [
    "Мы можем решать не только задачу классификации по темам, но и задачу классификации по тональности: можно классифицировать отзывы на негативный и позитивный классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "f7AF53Wl5f8W",
    "outputId": "50a52076-7d2b-4ce0-b95f-c9cf9a13b361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['negative', 'positive'],\n",
       " 'scores': [0.9916268587112427, 0.00837317667901516],\n",
       " 'sequence': 'I hated this movie. The acting sucked.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"I hated this movie. The acting sucked.\"\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSoBpCpV6k4s"
   },
   "source": [
    "\n",
    "Модель, лежащая в основе данного классификатора, была обучена на задаче Natural Language Inference (NLI). Задача состояла в следующем: по двум входящим текстам требовалось определить, является ли один из них продолжением другого.\n",
    "\n",
    "Такую модель можно использвать в задаче zero-shot классификации, если свести классификацию к задаче NLI. Для этого модели на вход подаются два текста:\n",
    "- текст, который нужно классифицировать (*предпосылка*)\n",
    "- текст шаблона, в который вставлено название нужного класса (*гипотеза*)\n",
    "\n",
    "\n",
    "Если с точки зрения NLI-модели текст гипотезы продолжает текст предпосылки, то мы можем заключить, что классифицируемый текст относится к соответствующему классу.\n",
    "\n",
    "По умолчанию заданные метки классов вставляются в шаблон `This example is {class_name}.` \n",
    "\n",
    "Во многих случаях такой подход работает достаточно хорошо, но в некоторых задачах качество классификации можно улучшить, используя более подходящий шаблон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "5yLx3pRr5xQA",
    "outputId": "6420fb46-9aeb-4055-8ab6-fdc5eb822a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': ['negative', 'positive'],\n",
       "  'scores': [0.9916267991065979, 0.008373182266950607],\n",
       "  'sequence': 'I hated this movie. The acting sucked.'},\n",
       " {'labels': ['negative', 'positive'],\n",
       "  'scores': [0.8148515820503235, 0.1851484179496765],\n",
       "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"I hated this movie. The acting sucked.\",\n",
    "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
    "]\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "classifier(sequences, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfrpyGWM782R"
   },
   "source": [
    "Второй пример выше несколько сложнее первого, поэтому модель предсказывает негативный класс менее уверенно. \n",
    "\n",
    "Попробуем повысить уверенность классификации, используя более подходящий шаблон для данной задачи. Вместо шаблона по умолчанию `This example is {}.`, мы будем использовать `The sentiment of this review is {}.` (здесь `{}` будет заменено на название класса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "kqx5hp7X8XNA",
    "outputId": "69c6e083-f3dc-41db-fca5-d96a3541f1fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': ['negative', 'positive'],\n",
       "  'scores': [0.9890093207359314, 0.010990672744810581],\n",
       "  'sequence': 'I hated this movie. The acting sucked.'},\n",
       " {'labels': ['positive', 'negative'],\n",
       "  'scores': [0.9581228494644165, 0.0418771356344223],\n",
       "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"I hated this movie. The acting sucked.\",\n",
    "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
    "]\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "hypothesis_template = \"The sentiment of this review is {}.\"\n",
    "\n",
    "classifier(sequences, candidate_labels, hypothesis_template=hypothesis_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iArbRAe781-_"
   },
   "source": [
    "\n",
    "Используя более точные и более подходящие к нашему контексту шаблоны, мы можем получить более точную классификацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxUTOnllSH4w"
   },
   "source": [
    "## Многоязычная классификация\n",
    "\n",
    "Данный классификатор можно использовать не только для английского языка, но и для ряда других. Для этого была обучена кросс-язычная модель на базе модели XLM RoBERTa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxUTOnllSH4w"
   },
   "source": [
    "Чтобы использовать эту модель, достаточно добавить дополнительный параметр ```model``` при объявлении классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siZhFPekSN7t"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model='joeddav/xlm-roberta-large-xnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrcljZ75UxKN"
   },
   "source": [
    "\n",
    "\n",
    "Модель позволяет использовать любую комбинацию языков. Можно, например, классифицировать русский текст с английскими названиями классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "gBJyFwC2TwGv",
    "outputId": "5e683b8a-2e9f-46c2-95f9-04559bed04ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politics', 'Europe', 'public health'],\n",
       " 'scores': [0.9048484563827515, 0.05722189322113991, 0.03792969882488251],\n",
       " 'sequence': 'За кого вы голосуете в 2020 году?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9hGVMsrVI8S"
   },
   "source": [
    "Теперь можно сделать то же самое, только поменять названия классов на французские."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "0xKYBOLYVeNJ",
    "outputId": "a8066bb5-9e95-4f80-d77b-9753cc4c4be3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politique', 'Europe', 'santé publique'],\n",
       " 'scores': [0.9726154804229736, 0.017128489911556244, 0.010256024077534676],\n",
       " 'sequence': 'За кого вы голосуете в 2020 году?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"Europe\", \"santé publique\", \"politique\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHURJUPCVgGP"
   },
   "source": [
    "\n",
    "Как было отмечено выше, по умолчанию в модели используется шаблон на английском языке, `This text is {}.`\n",
    "В случае, если мы работаем с другим языком, имеет смысл поменять данный шаблон на аналогичный, написанный на нужном нам языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "ZCtTclt7VpMv",
    "outputId": "87c768b3-2193-4164-d993-0ee9c9eec3ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['política', 'Europa', 'salud pública'],\n",
       " 'scores': [0.9109585881233215, 0.05954807624220848, 0.029493311420083046],\n",
       " 'sequence': '¿A quién vas a votar en 2020?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"¿A quién vas a votar en 2020?\"\n",
    "candidate_labels = [\"Europa\", \"salud pública\", \"política\"]\n",
    "hypothesis_template = \"Este ejemplo es {}.\"\n",
    "\n",
    "classifier(sequence, candidate_labels, hypothesis_template=hypothesis_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQyVNE2fTDVs"
   },
   "source": [
    "Модель была дообучена на корпусе XNLI, в состав которого входят тексты на 15 языках: английский, арабский, болгарский, вьетнамский, греческий, испанский, немецкий, русский, суахили, тайский, турецкий, урду, французский и хинди. \n",
    "\n",
    "Базовая модель RoBERTa, на основе которой была построена данная модель, была обучена на 100 языках, поэтому для каждого из этих языков эта модель будет также работать в некоторой степени.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcfDtTZBNmzh"
   },
   "source": [
    "## Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soiOHG3ONp-l"
   },
   "source": [
    "Сегодня мы познакомились с моделью на базе RoBERTa для решения задачи NLI.\n",
    "\n",
    "Мы научились использовать построенный на основе данной модели классификатор для классификации текстов на разных языках по разным классам, названия которых мы задавали сами.\n",
    "\n",
    "На следующих занятиях мы продолжим изучение моделей, основанных на архитектуре BERT и рассмотрим другие задачи, которые можем решать с их помощью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_zero-shot_classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
