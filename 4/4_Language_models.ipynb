{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Языковые модели и генерация текста </center></h1>\n",
    "\n",
    "1. Вероятностные модели\n",
    "2. Нейросетевые модели (RNN)\n",
    "\n",
    "#### Построим простую вероятностную языковую модель для генерации названий динозавров. \n",
    "Возьмем данные с реальными названиями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aachenosaurus\u001b=\n",
      "Aardonyx\n",
      "Abdallahsaurus\n",
      "Abelisaurus\n",
      "Abrictosaurus\n",
      "Abrosaurus\n",
      "Abydosaurus\n",
      "Acanthopholis\n",
      "Achelousaurus\n",
      "Acheroraptor\n",
      "Achillesaurus\n",
      "Achillobator\n",
      "Acristavus\n",
      "Acrocanthosaurus\n",
      "Acrotholus\n",
      "Actiosaurus\n",
      "Adamantisaurus\n",
      "Adasaurus\n",
      "Adelolophus\n",
      "Adeopapposaurus\n",
      "Aegyptosaurus\n",
      "Aeolosaurus\n",
      "Aepisaurus\n",
      "\u001b[KAepyornithomimus\u0007\n",
      ":\u001b[K"
     ]
    }
   ],
   "source": [
    "!less dinos.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['A', 'a', 'r', 'd', 'o', 'n', 'y', 'x'],\n",
       " ['A', 'b', 'd', 'a', 'l', 'l', 'a', 'h', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['A', 'b', 'e', 'l', 'i', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['A', 'b', 'r', 'i', 'c', 't', 'o', 's', 'a', 'u', 'r', 'u', 's']]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinos = []\n",
    "with open('dinos.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        dinos.append(list(line.strip()))\n",
    "\n",
    "dinos[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем учить модель для биграмм, поэтому нужно будет получить список биграмм для каждого слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'a'),\n",
       " ('a', 'c'),\n",
       " ('c', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', 'n'),\n",
       " ('n', 'o'),\n",
       " ('o', 's'),\n",
       " ('s', 'a'),\n",
       " ('a', 'u'),\n",
       " ('u', 'r'),\n",
       " ('r', 'u'),\n",
       " ('u', 's')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams, pad_sequence\n",
    "\n",
    "list(bigrams(dinos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо этого, нужно сообщить модели о начале и конце слова, поэтому добавим соответствующие символы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<', 'A', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '>']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pad_sequence(dinos[0], \n",
    "                  pad_left=True, \n",
    "                  left_pad_symbol=\"<\",\n",
    "                  pad_right=True, \n",
    "                  right_pad_symbol='>',\n",
    "                  n = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все это вместе можно сделать с помощью __padded_everygram_pipeline__ : этот метод создает итераторы для данных и словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "data, vocab = padded_everygram_pipeline(2, dinos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим часть данных для тестирования модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C', 'r', 'i', 'c', 'h', 't', 'o', 'n', 'p', 'e', 'l', 't', 'a'],\n",
       " ['S', 'k', 'o', 'r', 'p', 'i', 'o', 'v', 'e', 'n', 'a', 't', 'o', 'r'],\n",
       " ['D', 'r', 'i', 'n', 'k', 'e', 'r'],\n",
       " ['P', 'r', 'o', 'y', 'a', 'n', 'd', 'u', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['T', 'a', 's', 't', 'a', 'v', 'i', 'n', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['D', 'a', 'u', 'r', 'o', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['K', 'u', 'n', 'm', 'i', 'n', 'g', 'o', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['C', 'a', 'l', 'a', 'm', 'o', 's', 'p', 'o', 'n', 'd', 'y', 'l', 'u', 's'],\n",
       " ['R', 'u', 'b', 'e', 'o', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['D', 'a', 'x', 'i', 'a', 't', 'i', 't', 'a', 'n']]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(dinos)\n",
    "dinos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505, 31)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl = int(98*len(dinos)/100)\n",
    "train = dinos[:spl]\n",
    "test = dinos[spl:]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, vocab = padded_everygram_pipeline(2, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно обучать модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "lm = MLE(2) # 2 = наибольший размер используемых n-грамм\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(train_data, vocab)\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> <UNK> <s> A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(list(lm.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Абсолютная частота униграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.counts['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Абсолютная совместная частота биграммы 'Ab':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.counts[['A']]['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частота (вероятность) униграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007706945765937202"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частота (вероятность) биграмм 'bA' и 'Ab':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.030864197530864196)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(\"A\", [\"b\"]), lm.score(\"b\", [\"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно генериовать строки заданной длины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(1, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'c', 'e', 'l', 'o', 's']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(6, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'k', 'u', 's', 'h', 'i', 't', 'i', 'e', 'g']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(10, random_seed=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посчитать перплексию можели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.902702536398186"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [('<s>', 'A'), ('D', 'a')]\n",
    "\n",
    "lm.perplexity(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что перплексия для биграмм, которые не встречались в обучающией выборке, будет ожидаемо бесконечной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "print(lm.perplexity([('I', 'r')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issasaurus\n",
      "Indosuchus\n",
      "Ischioceratops\n",
      "Ilokelesia\n",
      "Iuticosaurus\n",
      "Iliosuchus\n",
      "Illustration\n",
      "Indosaurus\n",
      "Incisivosaurus\n",
      "Itemirus\n",
      "Isanosaurus\n",
      "Iguanodon\n",
      "Iguanosaurus\n",
      "Isaberrysaura\n",
      "Ischisaurus\n",
      "Ignavusaurus\n",
      "Isisaurus\n",
      "Ischyrosaurus\n",
      "Iguanacolossus\n",
      "Inosaurus\n",
      "Iguanoides\n"
     ]
    }
   ],
   "source": [
    "for t in train:\n",
    "    t_ = ''.join(t)\n",
    "    if t_.startswith('I'):\n",
    "        print(t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q', 'i', 'a', 'o', 'w', 'a', 'n', 'l', 'o', 'n', 'g'],\n",
       " ['T', 'o', 'n', 'g', 'a', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's'],\n",
       " ['C', 'a', 'l', 'l', 'o', 'v', 'o', 's', 'a', 'u', 'r', 'u', 's']]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Q', 'i', 'a', 'o', 'w', 'a', 'n', 'l', 'o', 'n', 'g', '</s>']\n",
      "['<s>', 'T', 'o', 'n', 'g', 'a', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '</s>']\n",
      "['<s>', 'C', 'a', 'l', 'l', 'o', 'v', 'o', 's', 'a', 'u', 'r', 'u', 's', '</s>']\n"
     ]
    }
   ],
   "source": [
    "padded_test = [['<s>']+t+['</s>'] for t in test]\n",
    "print(*padded_test[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'Q'),\n",
       " ('Q', 'i'),\n",
       " ('i', 'a'),\n",
       " ('a', 'o'),\n",
       " ('o', 'w'),\n",
       " ('w', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'l'),\n",
       " ('l', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', '</s>'),\n",
       " ('<s>', 'T'),\n",
       " ('T', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'o'),\n",
       " ('o', 's')]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_test = list(flatten([list(bigrams(t)) for t in padded_test]))\n",
    "bigrams_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(bigrams_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.272095348763163"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(padded_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно немного усложнить модель и учить условные вероятности для n-грамм при n = [2,3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C', 'r', 'i', 'c', 'h', 't', 'o', 'n', 'p', 'e', 'l', 't', 'a'],\n",
       " ['S', 'k', 'o', 'r', 'p', 'i', 'o', 'v', 'e', 'n', 'a', 't', 'o', 'r'],\n",
       " ['D', 'r', 'i', 'n', 'k', 'e', 'r']]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, vocab = padded_everygram_pipeline(3, train)\n",
    "\n",
    "\n",
    "lm = MLE(3)\n",
    "lm.fit(train_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'c', 'e', 'p', 'i', 'n', 's', '</s>']"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(8, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Q', 'i'),\n",
       " ('i', 'a'),\n",
       " ('a', 'o'),\n",
       " ('o', 'w'),\n",
       " ('w', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'l'),\n",
       " ('l', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'g')]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import everygrams\n",
    "\n",
    "padded_test = list(flatten([list(everygrams(t, 2, 3)) for t in test]))\n",
    "padded_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.72222331052448"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(padded_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь обучим нейросетевую языковую модель, а именно - рекуррентную нейросеть (RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinosDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.dinos = []\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                self.dinos.append('<'+line.strip()+'>')\n",
    "        self.vocab = sorted(set(''.join(self.dinos)))\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
    "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.dinos[index]\n",
    "        x_str = line[:-1] \n",
    "        y_str = line[1:]\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = DinosDataset('dinos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Aachenosaurus>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds.dinos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<': 0,\n",
       " '>': 1,\n",
       " 'A': 2,\n",
       " 'B': 3,\n",
       " 'C': 4,\n",
       " 'D': 5,\n",
       " 'E': 6,\n",
       " 'F': 7,\n",
       " 'G': 8,\n",
       " 'H': 9,\n",
       " 'I': 10,\n",
       " 'J': 11,\n",
       " 'K': 12,\n",
       " 'L': 13,\n",
       " 'M': 14,\n",
       " 'N': 15,\n",
       " 'O': 16,\n",
       " 'P': 17,\n",
       " 'Q': 18,\n",
       " 'R': 19,\n",
       " 'S': 20,\n",
       " 'T': 21,\n",
       " 'U': 22,\n",
       " 'V': 23,\n",
       " 'W': 24,\n",
       " 'X': 25,\n",
       " 'Y': 26,\n",
       " 'Z': 27,\n",
       " 'a': 28,\n",
       " 'b': 29,\n",
       " 'c': 30,\n",
       " 'd': 31,\n",
       " 'e': 32,\n",
       " 'f': 33,\n",
       " 'g': 34,\n",
       " 'h': 35,\n",
       " 'i': 36,\n",
       " 'j': 37,\n",
       " 'k': 38,\n",
       " 'l': 39,\n",
       " 'm': 40,\n",
       " 'n': 41,\n",
       " 'o': 42,\n",
       " 'p': 43,\n",
       " 'q': 44,\n",
       " 'r': 45,\n",
       " 's': 46,\n",
       " 't': 47,\n",
       " 'u': 48,\n",
       " 'v': 49,\n",
       " 'w': 50,\n",
       " 'x': 51,\n",
       " 'y': 52,\n",
       " 'z': 53}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds.ch_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([ 2, 28, 30, 35, 32, 41, 42, 46, 28, 48, 45, 48, 46,  1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = trn_ds[0]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 54]), torch.Size([14]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем модель, функцию потерь и алгоритм оптимизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, h_prev, x):\n",
    "        combined = torch.cat([h_prev, x], dim = 1) \n",
    "        h = torch.tanh(self.dropout(self.i2h(combined)))\n",
    "        y = self.i2o(h)\n",
    "        return h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    word_size=0\n",
    "    newline_idx = trn_ds.ch_to_idx['>']\n",
    "    with torch.no_grad():\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
    "        start_char_idx = trn_ds.ch_to_idx['<']\n",
    "        indices = [start_char_idx]\n",
    "        x[0, start_char_idx] = 1\n",
    "        predicted_char_idx = start_char_idx\n",
    "        \n",
    "        while predicted_char_idx != newline_idx and word_size != 50:\n",
    "            h_prev, y_pred = model(h_prev, x)\n",
    "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
    "            \n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
    "            indices.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            \n",
    "            predicted_char_idx = idx\n",
    "            \n",
    "            word_size += 1\n",
    "        \n",
    "        if word_size == 50:\n",
    "            indices.append(newline_idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample_idxs):\n",
    "    [print(trn_ds.idx_to_ch[x], end ='') for x in sample_idxs]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer, to_print = False):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            h_prev, y_pred = model(h_prev, x[:, i])\n",
    "            loss += loss_fn(y_pred, y[:, i])\n",
    "#         if to_print:    \n",
    "#             if (line_num+1) % 100 == 0:\n",
    "#                 print_sample(sample(model))\n",
    "           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if to_print:\n",
    "        perplexity = torch.exp(loss)\n",
    "        print(f'Perplexity:{perplexity}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        to_print = (e % 10 == 0)\n",
    "        if to_print:\n",
    "            print('\\nEpoch:{}'.format(e))\n",
    "        train_one_epoch(model, loss_fn, optimizer, to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:10\n",
      "Perplexity:440756187693056.0\n",
      "\n",
      "Epoch:20\n",
      "Perplexity:36634997293056.0\n",
      "\n",
      "Epoch:30\n",
      "Perplexity:9922272.0\n",
      "\n",
      "Epoch:40\n",
      "Perplexity:344076960.0\n",
      "\n",
      "Epoch:50\n",
      "Perplexity:516218304.0\n",
      "\n",
      "Epoch:60\n",
      "Perplexity:11184992.0\n",
      "\n",
      "Epoch:70\n",
      "Perplexity:17884070.0\n",
      "\n",
      "Epoch:80\n",
      "Perplexity:18009483264.0\n",
      "\n",
      "Epoch:90\n",
      "Perplexity:656356868096.0\n",
      "\n",
      "Epoch:100\n",
      "Perplexity:414842112.0\n",
      "\n",
      "Epoch:110\n",
      "Perplexity:103853466845184.0\n",
      "\n",
      "Epoch:120\n",
      "Perplexity:6808408064.0\n",
      "\n",
      "Epoch:130\n",
      "Perplexity:15185391616.0\n",
      "\n",
      "Epoch:140\n",
      "Perplexity:7774433.5\n",
      "\n",
      "Epoch:150\n",
      "Perplexity:62665492.0\n",
      "\n",
      "Epoch:160\n",
      "Perplexity:5.847457528073421e+16\n",
      "\n",
      "Epoch:170\n",
      "Perplexity:17389262848.0\n",
      "\n",
      "Epoch:180\n",
      "Perplexity:8231828992.0\n",
      "\n",
      "Epoch:190\n",
      "Perplexity:144977157947392.0\n",
      "\n",
      "Epoch:200\n",
      "Perplexity:10647029760.0\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Crgangsaurus>\n"
     ]
    }
   ],
   "source": [
    "print_sample(sample(model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
