{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wTjLOlc8ib0"
   },
   "source": [
    "<h1><center>Простые векторные модели текста</center></h1>\n",
    "\n",
    "<img src=\"pipeline_vec.png\" alt=\"pipeline.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "### Задача: классификация твитов по тональности\n",
    "\n",
    "В этом занятии мы познакомимся с распространенной задачей в анализе текстов: с классификацией текстов на классы.\n",
    "\n",
    "В рассмотренном тут примере классов будет два: положительный и отрицательный, такую постановку этой задачи обычно называют классификацией по тональности или sentiment analysis.\n",
    "\n",
    "Классификацию по тональности используют, например, в рекомендательных системах и при анализе отзывов клиентов, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Более подробно мы рассмотрим данную задачу и познакомимся с более сложными методами её решения в семинаре 3, а здесь разберем простые подходы, основанные на методе мешка слов.\n",
    "\n",
    "У нас есть [данные постов в твиттере](http://study.mokoron.com/), про из которых каждый указано, как он эмоционально окрашен: положительно или отрицательно. \n",
    "\n",
    "**Задача**: построить модель, которая по тексту поста предсказывает его эмоциональную окраску.\n",
    "\n",
    "\n",
    "Скачиваем данные: [положительные](https://drive.google.com/file/d/1mW_fUtYmRF19AXVySU0gJOIgx0-1EFgD/view?usp=sharing), [отрицательные](https://drive.google.com/file/d/1ZnsFuf-yfO3UEHlIpk7TTqfKkEMdm1EQ/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuDVGp4O8ib1",
    "outputId": "11001569-4329-4c75-f8f0-2c5ec63708b2"
   },
   "outputs": [],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1mW_fUtYmRF19AXVySU0gJOIgx0-1EFgD' -O positive.csv\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ZnsFuf-yfO3UEHlIpk7TTqfKkEMdm1EQ' -O negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPp8_2Sy8ib5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsmSQOE98ib8"
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc9rKWk8ib-",
    "outputId": "ad6faf65-5361-434d-a46d-a7c176603a14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16748</th>\n",
       "      <td>Лес рук, зажигалки, флаги)) #lumen #glavclub #главclub @ ГлавClub http://t.co/YTWzMFnrkt</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91284</th>\n",
       "      <td>Влюбиться отменяется. Завтра по плану отличная посиделка с кальяном после работы^_^</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97845</th>\n",
       "      <td>@aruslanmager )) она на такие слова ещё и обижается</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95348</th>\n",
       "      <td>#юмор ска только 675(( чувакии поднажмите пожааалуйста:33</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72398</th>\n",
       "      <td>однако :D \\nузнала о себе\\nТы учишь немецкий, живёшь в России... Но тебе пошло бы быть англичанкой.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text     label\n",
       "16748             Лес рук, зажигалки, флаги)) #lumen #glavclub #главclub @ ГлавClub http://t.co/YTWzMFnrkt  positive\n",
       "91284                  Влюбиться отменяется. Завтра по плану отличная посиделка с кальяном после работы^_^  positive\n",
       "97845                                                  @aruslanmager )) она на такие слова ещё и обижается  positive\n",
       "95348                                            #юмор ска только 675(( чувакии поднажмите пожааалуйста:33  negative\n",
       "72398  однако :D \\nузнала о себе\\nТы учишь немецкий, живёшь в России... Но тебе пошло бы быть англичанкой.  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся функцией для предобработки текста, которую мы написали в прошлом семинаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return regex.findall(text.lower())\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(token, pymorphy=m):\n",
    "    return pymorphy.parse(token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatize_word(w) for w in text]\n",
    "\n",
    "\n",
    "mystopwords = stopwords.words('russian') \n",
    "def remove_stopwords(lemmas, stopwords = mystopwords):\n",
    "    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = words_only(text)\n",
    "    lemmas = lemmatize_text(tokens)\n",
    "    \n",
    "    return ' '.join(remove_stopwords(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226834/226834 [01:52<00:00, 2019.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74560</th>\n",
       "      <td>RT @kostossi: @VechernijUrgant за здоровый образ жизни ! Только каши , льняная подойдет :)</td>\n",
       "      <td>positive</td>\n",
       "      <td>[kostossi, vechernijurgant, здоровый, образ, жизнь, каша, льняной, подойти]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>))))Я хочу незабываемый Новый год. Много-много снега и близких людей рядом.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[хотеть, незабываемый, новый, снег, близкие, человек]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74689</th>\n",
       "      <td>@KSHN мучают бедную слониху, изверги. Издеваются подлые твари (((((</td>\n",
       "      <td>negative</td>\n",
       "      <td>[kshn, мучить, бедный, слониха, изверг, издеваться, подлый, тварь]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51237</th>\n",
       "      <td>Оцарапала гитару медиатором при игре( надеюсь все хорошо будет с ней! Потому что не слабо!</td>\n",
       "      <td>negative</td>\n",
       "      <td>[оцарапать, гитара, медиатор, игра, надеяться, весь, слабо]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13634</th>\n",
       "      <td>Двадцать на двадцать.\\n\"Программа\" в #kz есть такая.)</td>\n",
       "      <td>positive</td>\n",
       "      <td>[двадцать, двадцать, программа]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             text     label                                                                       lemmas\n",
       "74560  RT @kostossi: @VechernijUrgant за здоровый образ жизни ! Только каши , льняная подойдет :)  positive  [kostossi, vechernijurgant, здоровый, образ, жизнь, каша, льняной, подойти]\n",
       "6135                  ))))Я хочу незабываемый Новый год. Много-много снега и близких людей рядом.  positive                        [хотеть, незабываемый, новый, снег, близкие, человек]\n",
       "74689                         @KSHN мучают бедную слониху, изверги. Издеваются подлые твари (((((  negative           [kshn, мучить, бедный, слониха, изверг, издеваться, подлый, тварь]\n",
       "51237  Оцарапала гитару медиатором при игре( надеюсь все хорошо будет с ней! Потому что не слабо!  negative                  [оцарапать, гитара, медиатор, игра, надеяться, весь, слабо]\n",
       "13634                                       Двадцать на двадцать.\\n\"Программа\" в #kz есть такая.)  positive                                              [двадцать, двадцать, программа]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "with Pool(4) as p:\n",
    "    lemmas = list(tqdm(p.imap(clean_text, df['text']), total=len(df)))\n",
    "    \n",
    "df['lemmas'] = lemmas\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на train и test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3MD0bex8icC"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.lemmas, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ppAtTFc8icE"
   },
   "source": [
    "## Мешок слов (Bag of Words, BoW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gJLFKQ38icE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AMGIJ8C8icH"
   },
   "source": [
    "... Но сперва пару слов об n-граммах. Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0-y2A6k8icH"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_lgEYzY8icJ",
    "outputId": "f9d482bd-0c45-4830-9e7b-1b49d1290468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDRi-68C8icM",
    "outputId": "8d04b779-f404-4c5e-e06c-125ef4f4572d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaUeKBDh8icO",
    "outputId": "831fbc23-1c08-4b7b-e5fd-856c10132bdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z325_XfX8icS",
    "outputId": "5da7999f-0cf3-4964-8d23-e958f21d5f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80h0e8FJ8icV"
   },
   "source": [
    "Итак, мы хотим преобразовать наши обработанные данные в вектора с помощью мешка слов. Мешок слов можно строить как для отдельных слов (лемм в нашем случае), так и для n-грамм, и это может улучшать качество. \n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SQaMJbl8icW"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1)) # строим BoW для слов\n",
    "bow = vec.fit_transform(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6eZOyAf8icY"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве признаков:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: соответствие слов и их индексов в словаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8cncS9M8icY",
    "outputId": "c1943f5c-3400-4fb1-d218-c8f89d225634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('докторша', 108072),\n",
       " ('говорить', 104475),\n",
       " ('поликлинник', 140005),\n",
       " ('милый', 125025),\n",
       " ('красивый', 119704),\n",
       " ('урурурур', 160311),\n",
       " ('мило', 124998),\n",
       " ('sopli', 73121),\n",
       " ('back', 9457),\n",
       " ('средневековье', 153620)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x169087 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть вектора, на которых можно обучать модели! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Rq60E68ica",
    "outputId": "5caa0b70-3a96-4efb-f241-93120aa9f362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=500)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество классификации на тестовой выборке. Для этого выведем classification_report из модуля [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n",
    "В качестве целевой метрики качества будем рассматривать macro average f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xf8gqHSD8icc",
    "outputId": "71a8da2f-d5c6-4070-b28e-d99cc7145832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.73     28300\n",
      "    positive       0.73      0.74      0.74     28409\n",
      "\n",
      "    accuracy                           0.74     56709\n",
      "   macro avg       0.74      0.74      0.74     56709\n",
      "weighted avg       0.74      0.74      0.74     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdoG6YCr8icf"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GUDAWcz8icg",
    "outputId": "88bfc3b3-7eb9-4082-f500-84d75c2e3d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.53      0.68     51145\n",
      "    positive       0.16      0.84      0.27      5564\n",
      "\n",
      "    accuracy                           0.56     56709\n",
      "   macro avg       0.56      0.68      0.48     56709\n",
      "weighted avg       0.89      0.56      0.64     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество существенно хуже. Ниже мы поймем, почему это так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4PTszK9h8ick"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ9Td4bw8icm"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Ключевая идея этого подхода – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8B_Q8qP8icm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn-S--vi8ico",
    "outputId": "42455755-3c0c-4ab2-c08d-caf318cad0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.74      0.72     26124\n",
      "    positive       0.77      0.72      0.74     30585\n",
      "\n",
      "    accuracy                           0.73     56709\n",
      "   macro avg       0.73      0.73      0.73     56709\n",
      "weighted avg       0.73      0.73      0.73     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 500)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXglD7lb8icq"
   },
   "source": [
    "В этот раз получилось хуже, чем с помощью простого CountVectorizer, то есть использование tf-idf не дало улучшений в качестве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETq8X_Tb8idz"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Иногда в ходе стандартного препроцессинга теряются важные признаки. Посмотрим, что будет если не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106338</th>\n",
       "      <td>Короче, удивила Москва меня ! Да так-то тут нормально)</td>\n",
       "      <td>positive</td>\n",
       "      <td>короче удивить москва нормальный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          text     label                            lemmas\n",
       "106338  Короче, удивила Москва меня ! Да так-то тут нормально)  positive  короче удивить москва нормальный"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>new_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91634</th>\n",
       "      <td>@AdolfNastya у нас было -20 \\nчто ты знаешь о морозе?:D</td>\n",
       "      <td>positive</td>\n",
       "      <td>adolfnastya знаешь мороз</td>\n",
       "      <td>@adolfnastya у нас было -20 \\nчто ты знаешь о морозе?:d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35566</th>\n",
       "      <td>@Florida_1995 @Shutova4Real значит, курочки, да? это ты на наши умственные способности намекаешь? :D хорошо, что хоть любимые) ахаха</td>\n",
       "      <td>positive</td>\n",
       "      <td>florida_ shutova real значит курочка умственный способность намекать любимый ахах</td>\n",
       "      <td>@florida_1995 @shutova4real значит, курочки, да? это ты на наши умственные способности намекаешь? :d хорошо, что хоть любимые) ахаха</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81916</th>\n",
       "      <td>ты загодала желание?- нет ! - почему?- мне не  надо загадывать ты уже со мной!!!!)))</td>\n",
       "      <td>positive</td>\n",
       "      <td>загодать желание почему загадывать</td>\n",
       "      <td>ты загодала желание?- нет ! - почему?- мне не  надо загадывать ты уже со мной!!!!)))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text     label                                                                             lemmas                                                                                                                            new_lemmas\n",
       "91634                                                                               @AdolfNastya у нас было -20 \\nчто ты знаешь о морозе?:D  positive                                                           adolfnastya знаешь мороз                                                                               @adolfnastya у нас было -20 \\nчто ты знаешь о морозе?:d\n",
       "35566  @Florida_1995 @Shutova4Real значит, курочки, да? это ты на наши умственные способности намекаешь? :D хорошо, что хоть любимые) ахаха  positive  florida_ shutova real значит курочка умственный способность намекать любимый ахах  @florida_1995 @shutova4real значит, курочки, да? это ты на наши умственные способности намекаешь? :d хорошо, что хоть любимые) ахаха\n",
       "81916                                                  ты загодала желание?- нет ! - почему?- мне не  надо загадывать ты уже со мной!!!!)))  positive                                                 загодать желание почему загадывать                                                  ты загодала желание?- нет ! - почему?- мне не  надо загадывать ты уже со мной!!!!)))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_lemmas'] = df.text.apply(lambda x: x.lower())\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.new_lemmas, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ue0DUsX18id0",
    "outputId": "f3858c1f-554f-4f18-8cc4-6fa5416702ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27825\n",
      "    positive       1.00      1.00      1.00     28884\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter = 300)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wymeD7-B8id3"
   },
   "source": [
    "Как можно видеть, если оставить пунктуацию, то все метрики равны 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259979, 259979)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.vocabulary_), len(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGKuAvYR8id3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@', 0.11768651169721642)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = list(zip(vec.vocabulary_, clf.coef_[0]))\n",
    "importances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('есть', 58.39173024498836),\n",
       " ('foxellanseva', 26.9157592150693),\n",
       " ('чуваку', 10.576893100095987),\n",
       " ('theirinali', 9.096114872867306),\n",
       " ('рта', 7.8846010394951085),\n",
       " ('событий', 7.811647650160388),\n",
       " (')', 7.102713299790951),\n",
       " ('лжецы', 6.178342975649683),\n",
       " ('освободились', 4.904776606595675),\n",
       " ('сформулировать', 3.0981650553247335)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_importances = sorted(importances, key = lambda x: -x[1])\n",
    "sorted_importances[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QxmioaZ8id8"
   },
   "source": [
    "Посмотрим, как один из наиболее значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17LPHPGR8id9",
    "outputId": "50c87666-43d1-401e-fef9-c19d4faa5e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32706\n",
      "    positive       0.83      1.00      0.91     24003\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.92      0.93      0.91     56709\n",
      "weighted avg       0.93      0.91      0.92     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что это уже позволяет достаточно хорошо классифицировать тексты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7VjSCog8id_"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве признаком используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSO-k4wA8id_",
    "outputId": "29b7529b-d86c-466a-802d-186284782503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99     27742\n",
      "    positive       1.00      0.99      0.99     28967\n",
      "\n",
      "    accuracy                           0.99     56709\n",
      "   macro avg       0.99      0.99      0.99     56709\n",
      "weighted avg       0.99      0.99      0.99     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i6JwqL-8ieE"
   },
   "source": [
    "Таким образом, становится понятно, почему на этих данных качество классификации 1. Так или иначе, на символах классифицировать тоже можно.\n",
    "\n",
    "Ещё одна замечательная особенность символьных признаков: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    " На этом занятии мы\n",
    "* познакомились с задачей бинарной классификации текстов.\n",
    "\n",
    "* научились строить простые признаки на основе метода \"мешка слов\" с помощью библиотеки sklearn: CountVectorizer и TfidfVectorizer.\n",
    "\n",
    "* использовали для классификации линейную модель логистической регрессии.\n",
    "\n",
    "* поняли, что многое зависит от подхода к предобработки текста и от признаков, которые используются в модели.\n",
    "\n",
    "* увидели, что в некоторых задачах важно использование каждого символа из текста, в том числе пунктуации.\n",
    "\n",
    "На следующих занятиях мы рассмотрим более сложные модели построения признаков и классификации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
